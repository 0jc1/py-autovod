# Main configuration file

[streamers]
# List of streamers, comma-separated
streamers = theburntpeanut, deslic

[general]
# Time in seconds to wait between checks if a stream is offline
retry_delay = 120

version = 1.0.0

[transcription]
# Enable or disable automatic transcription of downloaded streams
enabled = true

device = cuda  # cuda, cpu

# Whisper model size (tiny, base, small, medium, large)
model_size = base

# Clean up temporary WAV files after transcription
cleanup_wav = false

[llm]
# openai/o3, openai/gpt-4.1, deepseek/deepseek-chat, google/gemini-2.5-pro-preview-03-25
model_name = deepseek/deepseek-chat

# Lower temperature for more structured output
temperature = 0.5

max_tokens = 1000