# Main configuration file

[streamers]
# List of streamers, comma-separated
streamers = adinross

[general]
# Time in seconds to wait between checks if a streamer is offline
retry_delay = 120

# Program version
version = 1.0.1

[clipception]

enabled = false

# Duration of clips in seconds
clip_duration = 90.0

# Default number of clips to generate per video
num_clips = 10  

[clipception.transcription]
# cuda, cpu
device = cuda  

# Whisper model size (tiny, base, small, medium, large)
model_size = base

# Clean up temporary WAV files after transcription
cleanup_wav = false

[clipception.llm]
# OpenRouter LLM model (openai/o3, openai/gpt-4.1, deepseek/deepseek-chat, deepseek/deepseek-chat:free, google/gemini-2.5-pro-preview-03-25)
model_name = deepseek/deepseek-chat

# Lower temperature for more structured output (0-1)
temperature = 0.5

max_tokens = 1000